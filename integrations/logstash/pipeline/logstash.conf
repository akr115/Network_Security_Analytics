input {
    beats {
        port => 6000
    }
}

filter {
    # Clean up the event and extract the CSV array
    mutate {
        rename => { "[decoded][csv]" => "[csv]" }
        remove_field => [
            "@version",
            "@timestamp",
            "agent",
            "ecs",
            "event",
            "host",
            "input",
            "log",
            "message",
            "tags",
            "decoded"
        ]
    }

    # Drop events that do not have exactly 82 fields
    ruby {
        code => "
        if event.get('csv').nil? || event.get('csv').length != 82
            event.cancel
        end
        "
    }

    # Send CSV to FastAPI for prediction
    http {
        url => "http://predictor_api:8000/predict/csv"
        verb => "POST"
        format => "json"
        target_body => "prediction_result"  # store FastAPI response here
        headers => {
            "Content-Type" => "application/json"
        }
        body => '{"csv": %{[csv]}}'
        read_timeout => 5
        open_timeout => 2
    }

    # Flatten the prediction to top-level
    mutate {
        add_field => { "prediction" => "%{[prediction_result][prediction]}" }
        remove_field => ["prediction_result"]  # optional cleanup
    }
}

output {
    # # Forward enriched event to Elasticsearch
    # elasticsearch {
    #     hosts => ["http://elasticsearch:9200"]
    #     index => "network-predictions"
    # }

    # Optional: debug output
    stdout {
        codec => rubydebug
    }
}
